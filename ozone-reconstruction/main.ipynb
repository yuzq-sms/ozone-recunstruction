{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,root_mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df=pd.read_csv(\"prepare_2014-2022.csv\",index_col=0)\n",
    "mask = (df['longitude'] > 119.5) & (df['latitude'] < 26.5)\n",
    "\n",
    "# 删除这些行\n",
    "df = df[~mask]\n",
    "df = df[df['exact_time'] >= 998406]\n",
    "a12=pd.read_csv(\"E:\\\\2023\\\\weather\\\\main\\\\O3finish\\\\allO3_2013.csv\",index_col=0)\n",
    "#a12=a12[a12['time'] == 990558]\n",
    "a12= a12.reset_index(drop=True)\n",
    "print(a12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.isin([ -9999.0]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_year(df, year,ww):\n",
    "    # 基准时间\n",
    "    base_time = pd.Timestamp('1900-01-01 00:00:00')\n",
    "    \n",
    "    # 将 'exact_time' 转换为实际的日期时间\n",
    "    df['datetime'] = base_time + pd.to_timedelta(df['exact_time'], unit='h')\n",
    "    \n",
    "    # 筛选出指定年份的数据\n",
    "    if ww:\n",
    "        filtered_df = df[df['datetime'].dt.year == year]\n",
    "    else:\n",
    "        filtered_df = df[df['datetime'].dt.year != year]\n",
    "    \n",
    "    # 删除辅助的 'datetime' 列，保持原表格格式\n",
    "    filtered_df = filtered_df.drop(columns=['datetime'])\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num\"]=(df[\"longitude\"]-100)*2+47*(df[\"latitude\"]-20)\n",
    "yearsd=2019\n",
    "new_names = {col: re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns}\n",
    "new_n_list = list(new_names.values())\n",
    "# [LightGBM] Feature appears more than one time.\n",
    "new_names = {col: f'{new_col}_{i}' if new_col in new_n_list[:i] else new_col for i, (col, new_col) in enumerate(new_names.items())}\n",
    "gdf=df.copy()\n",
    "\n",
    "gdf = gdf.rename(columns=new_names)\n",
    "y = gdf.iloc[:, [0,3]]\n",
    "\n",
    "gdf.drop(df.columns[3], axis=1, inplace=True)\n",
    "gdf.drop(['longitude', 'latitude'], axis=1, inplace=True)\n",
    "gdf.drop(['num'], axis=1, inplace=True)\n",
    "X = gdf\n",
    "X_less=X.iloc[:,:]\n",
    "X_less=X_less.iloc[:,:]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_less.iloc[:,1:], y.iloc[:,1], test_size=0.2,random_state=42)\n",
    "\n",
    "X_test=filter_by_year(X_less,yearsd,True)\n",
    "X_test=X_test.iloc[:,1:]\n",
    "X_train = filter_by_year(X_less,yearsd,False)\n",
    "X_train = X_train.iloc[:,1:]\n",
    "y_test=filter_by_year(y,yearsd,True)\n",
    "y_test=y_test.iloc[:,1]\n",
    "y_train = filter_by_year(y,yearsd,False)\n",
    "y_train=y_train.iloc[:,1]\n",
    "print(y_test)\n",
    "# 转换为Dataset数据格式\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression',  # 回归任务\n",
    "    'metric': {'l2', 'auc'},  # 评估函数\n",
    "    'num_leaves': 20000,  # 叶子节点数\n",
    "    'learning_rate': 0.1,  # 学习速率\n",
    "    'feature_fraction': 0.95,  # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.95,  # 建树的样本采样比例\n",
    "    'bagging_freq': 2,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1 , # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "    'device': 'gpu'\n",
    "}\n",
    "\n",
    "# 模型训练\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=20, valid_sets=lgb_eval)\n",
    "\n",
    "# 模型保存\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "# 模型加载\n",
    "gbm = lgb.Booster(model_file='model.txt')\n",
    "\n",
    "# 模型预测\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "# 模型评估\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 for test set: {r2_test:.4f}\")\n",
    "\n",
    "all_elements = list(range(len(y_test)))\n",
    "    \n",
    "# 随机打乱列表的顺序\n",
    "random.shuffle(all_elements)\n",
    "y_test=np.array(y_test)\n",
    "y_train=np.array(y_train)\n",
    "# 选取前100个元素作为索引\n",
    "selected_indices = all_elements[:1000]\n",
    "print(\"drawing\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(x=y_test[selected_indices], y=y_pred[selected_indices], fill=True, cmap='viridis', cbar=True, label=\"Test Set\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"with_space_and_time_2013\")\n",
    "plt.plot([20, 200], [20, 200], color='gray', linestyle='--', label=\"x=y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 模型预测\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "\n",
    "# 模型评估\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 for test set: {r2_test:.4f}\")\n",
    "\n",
    "all_elements = list(range(len(y_test)))\n",
    "    \n",
    "# 随机打乱列表的顺序\n",
    "random.shuffle(all_elements)\n",
    "y_test=np.array(y_test)\n",
    "y_train=np.array(y_train)\n",
    "# 选取前100个元素作为索引\n",
    "selected_indices = all_elements[:1000]\n",
    "print(\"drawing\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(x=y_test[selected_indices], y=y_pred[selected_indices], fill=True, cmap='viridis', cbar=True, label=\"Test Set\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"with_space_and_time_2013\")\n",
    "plt.plot([20, 200], [20, 200], color='gray', linestyle='--', label=\"x=y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=filter_by_year(X_less,yearsd,True)\n",
    "X_train = filter_by_year(X_less,yearsd,False)\n",
    "y_test=filter_by_year(y,yearsd,True)\n",
    "y_test=y_test.iloc[:,1]\n",
    "y_train = filter_by_year(y,yearsd,False)\n",
    "y_train=y_train.iloc[:,1]\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_less.iloc[:,:], y.iloc[:,1], test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "y_more=X_test.iloc[:,[0,1,2,3]]\n",
    "y_more = y_more.reset_index(drop=True) \n",
    "\n",
    "\n",
    "y_pred_frame = pd.DataFrame({'O3_pred': y_pred})\n",
    "y_pred_frame=y_pred_frame.reset_index(drop=True)\n",
    "y_test_frame=  pd.DataFrame({\"O3_true\":y_test})\n",
    "y_test_frame=y_test_frame.reset_index(drop=True)\n",
    "result_df = pd.concat([y_more, y_pred_frame], axis=1)\n",
    "result_df = result_df.drop(result_df.columns[3], axis=1)\n",
    "original_df=pd.concat([y_more, y_test_frame], axis=1)\n",
    "original_df = original_df.drop(original_df.columns[3], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df)\n",
    "result_df.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算相关系数、RMSE和MAE\n",
    "r2 = r2_score(original_df[\"O3_true\"], result_df[\"O3_pred\"])\n",
    "rmse = mean_squared_error(original_df[\"O3_true\"], result_df[\"O3_pred\"], squared=False)  # squared=False表示计算RMSE\n",
    "mae = mean_absolute_error(original_df[\"O3_true\"], result_df[\"O3_pred\"])\n",
    "x_range = np.arange(20, 43.5, 0.5)\n",
    "y_range = np.arange(100, 123.5, 0.5)\n",
    "\n",
    "\n",
    "# 创建网格数据\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "result_temp= np.column_stack((xx.ravel(), yy.ravel()))\n",
    "np.set_printoptions(precision=1,suppress=True)\n",
    "\n",
    "aa=pd.DataFrame(result_temp,columns=[\"latitude\",\"longitude\"])\n",
    "aa[\"rmse\"]=0.0\n",
    "aa[\"mae\"]=0.0\n",
    "aa[\"r2\"]=0.0\n",
    "sorted_aa = aa.sort_values(by=[\"latitude\",\"longitude\"])\n",
    "print(aa)\n",
    "for i in range(0,len(aa)):\n",
    "    lon1=aa.iloc[i,1];lat1=aa.iloc[i,0]\n",
    "    # 筛选DataFrame\n",
    "    filtered_ori = original_df[(original_df['longitude'] == lon1) & (original_df['latitude'] == lat1)]\n",
    "\n",
    "    # 检查筛选后的DataFrame是否为空\n",
    "    if filtered_ori.empty:\n",
    "        shabizhouxianrong=1+1\n",
    "    else:\n",
    "        filtered_result = result_df[(result_df['longitude'] == lon1) & (result_df['latitude'] == lat1)]\n",
    "\n",
    "        aa.iloc[i,4]=r2_score(filtered_ori[\"O3_true\"], filtered_result[\"O3_pred\"])\n",
    "        aa.iloc[i,2]=root_mean_squared_error(filtered_ori[\"O3_true\"], filtered_result[\"O3_pred\"])\n",
    "        aa.iloc[i,3]=mean_absolute_error(filtered_ori[\"O3_true\"], filtered_result[\"O3_pred\"])\n",
    "aa.to_csv(\".\\\\output\\\\\"+str(yearsd)+\"_pointwise_r2_rmse_mae.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "# Assuming 'exact_time' is in hours since '1900-01-01 00:00:00.0'\n",
    "base_time = pd.Timestamp('1900-01-01 00:00:00')\n",
    "\n",
    "# First, ensure 'exact_time' is treated as numeric (hours since base_time)\n",
    "result_df['exact_time'] = pd.to_numeric(result_df['exact_time'])\n",
    "\n",
    "# Calculate the actual datetime from hours since base_time\n",
    "result_df['exact_time'] = base_time + pd.to_timedelta(result_df['exact_time'], unit='h')\n",
    "\n",
    "# Set up the dimensions and variable for xarray\n",
    "ds = result_df.set_index(['exact_time', 'latitude', 'longitude']).to_xarray()\n",
    "\n",
    "# Save the Dataset as a NetCDF file\n",
    "output_path = \".//output//\"+\"result_\"+str(yearsd)+\".nc\"\n",
    "ds.to_netcdf(output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'exact_time' is in hours since '1900-01-01 00:00:00.0'\n",
    "base_time = pd.Timestamp('1900-01-01 00:00:00')\n",
    "\n",
    "# First, ensure 'exact_time' is treated as numeric (hours since base_time)\n",
    "original_df['exact_time'] = pd.to_numeric(original_df['exact_time'])\n",
    "\n",
    "# Calculate the actual datetime from hours since base_time\n",
    "original_df['exact_time'] = base_time + pd.to_timedelta(original_df['exact_time'], unit='h')\n",
    "\n",
    "# Set up the dimensions and variable for xarray\n",
    "ds = original_df.set_index(['exact_time', 'latitude', 'longitude']).to_xarray()\n",
    "\n",
    "# Save the Dataset as a NetCDF file\n",
    "output_path = \".//output//\"+\"original_\"+str(yearsd)+\".nc\"\n",
    "ds.to_netcdf(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "# 打开.nc文件\n",
    "dataset = nc.Dataset(output_path)\n",
    "\n",
    "# 查看文件中的变量\n",
    "variables = dataset.variables\n",
    "for var_name in variables:\n",
    "    var = dataset.variables[var_name]\n",
    "    print(f'变量名: {var_name}')\n",
    "    print(f'维度: {var.dimensions}')\n",
    "    print(f'形状: {var.shape}')\n",
    "    print(f'属性: {var.ncattrs()}')\n",
    "    for attr_name in var.ncattrs():\n",
    "        print(f'{attr_name}: {getattr(var, attr_name)}')\n",
    "\n",
    "variable_names = list(dataset.variables.keys())\n",
    "\n",
    "# 打印变量名列表\n",
    "print(variable_names)\n",
    "\n",
    "# 关闭文件\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \".//output//\"+\"result_\"+str(yearsd)+\".nc\"\n",
    "# Load the NetCDF file\n",
    "file_path = output_path # Replace with the path to your NetCDF file\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Check the available 'exact_time' values\n",
    "print(ds['exact_time'])\n",
    "\n",
    "# Select a specific date (e.g., the first date in the dataset)\n",
    "selected_date = ds['exact_time'].isel(exact_time=60)  # Change index to select the desired date\n",
    "\n",
    "# Extract the 'O3_true' data for the selected date\n",
    "o3_data = ds['O3_pred'].sel(exact_time=selected_date)\n",
    "\n",
    "# Create a plot of 'O3_true' for the selected date\n",
    "plt.figure(figsize=(10, 6))\n",
    "o3_data.plot(x='longitude', y='latitude', cmap='viridis')  # Use x as longitude and y as latitude\n",
    "plt.title(f'O3_true on {selected_date.values}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.colorbar(label='O3_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \".//output//\"+\"original_\"+str(yearsd)+\".nc\"\n",
    "# Load the NetCDF file\n",
    "file_path = output_path # Replace with the path to your NetCDF file\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Check the available 'exact_time' values\n",
    "print(ds['exact_time'])\n",
    "\n",
    "# Select a specific date (e.g., the first date in the dataset)\n",
    "selected_date = ds['exact_time'].isel(exact_time=60)  # Change index to select the desired date\n",
    "\n",
    "# Extract the 'O3_true' data for the selected date\n",
    "o3_data = ds['O3_true'].sel(exact_time=selected_date)\n",
    "\n",
    "# Create a plot of 'O3_true' for the selected date\n",
    "plt.figure(figsize=(10, 6))\n",
    "o3_data.plot(x='longitude', y='latitude', cmap='viridis')  # Use x as longitude and y as latitude\n",
    "plt.title(f'O3_true on {selected_date.values}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.colorbar(label='O3_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 指定时间范围\n",
    "start_time = 0\n",
    "end_time = 2160*4\n",
    "\n",
    "# 筛选符合时间范围的数据\n",
    "filtered_df1 = result_df\n",
    "print(result_df)\n",
    "\n",
    "# 按[\"longitude\", \"latitude\"]组合计算平均值\n",
    "grouped_df1 = filtered_df1.groupby(['longitude', 'latitude'])['O3_pred'].mean().reset_index()\n",
    "\n",
    "\n",
    "filtered_df2 = original_df\n",
    "\n",
    "# 按[\"longitude\", \"latitude\"]组合计算平均值\n",
    "grouped_df2 = filtered_df2.groupby(['longitude', 'latitude'])['O3_true'].mean().reset_index()\n",
    "\n",
    "\n",
    "# 指定时间范围\n",
    "temp_data1_df=original_df.copy()\n",
    "temp_data1_df[\"O3_true\"]=(result_df[\"O3_pred\"]-original_df[\"O3_true\"])/1\n",
    "#original_df[\"O3_true\"]=(result_df[\"O3_pred\"]-original_df[\"O3_true\"])/2\n",
    "# 筛选符合时间范围的数据\n",
    "# filtered_df2 = original_df[(original_df['time'] >= start_time) & (original_df['time'] <= end_time)]\n",
    "\n",
    "# # 按[\"longitude\", \"latitude\"]组合计算平均值\n",
    "# grouped_df2 = filtered_df2.groupby(['longitude', 'latitude'])['O3_true'].mean().reset_index()\n",
    "filtered_df3 = temp_data1_df\n",
    "\n",
    "# 按[\"longitude\", \"latitude\"]组合计算平均值\n",
    "grouped_df3 = filtered_df3.groupby(['longitude', 'latitude'])['O3_true'].mean().reset_index()\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='O3_pred', size='O3_pred', data=grouped_df1, palette='coolwarm', legend='brief')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Q3 2017 mean error(pred-original)(without emmision)')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='O3_true', size='O3_true', data=grouped_df2, palette='coolwarm', legend='brief')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Q3 2017 mean error(pred-original)(without emmision)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgb-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
